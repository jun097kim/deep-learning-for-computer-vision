{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MNIST 데이터 로드하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST_data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST_data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST_data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "# 레이블은 정수 형태이지만, 훈련을 위해서 one-hot 인코딩으로 로드\n",
    "mnist_data = input_data.read_data_sets('MNIST_data', one_hot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 퍼셉트론 구축하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. 입력 데이터와 타깃을 위한 플레이스홀더 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "no_classes = 10\n",
    "batch_size = 100\n",
    "total_batches = 200\n",
    "\n",
    "# batch size X input_size\n",
    "x_input = tf.placeholder(tf.float32, shape=[None, input_size])\n",
    "# batch_size X no_classes. one-hot label\n",
    "y_input = tf.placeholder(tf.float32, shape=[None, no_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Fully-connected Layer를 위한 변수 정의하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_size X no_classes (각 픽셀과 클래스 사이의 weight)\n",
    "weights = tf.Variable(tf.random_normal([input_size, no_classes]))\n",
    "# no_classes X 1 (클래스 수와 동일)\n",
    "bias = tf.Variable(tf.random_normal([no_classes]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 입력 값에 weight를 부여하고 bias 값 추가\n",
    "# 각각의 입력 데이터가 어떤 클래스에 해당하는지 예측하고 bias 추가\n",
    "\n",
    "# 행렬간 곱셈 = batch size X no_classes\n",
    "logits = tf.matmul(x_input, weights) + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# logits과 y_input 비교\n",
    "softmax_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=y_input, logits=logits)\n",
    "# cross entropy의 평균으로 loss 계산\n",
    "loss_operation = tf.reduce_mean(softmax_cross_entropy)\n",
    "# loss_operation이 minimize되도록 weights, bias 학습\n",
    "optimizer = tf.train.GradientDescentOptimizer(\n",
    "    learning_rate=0.5).minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. 데이터로 모델 훈련하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.327893\n",
      "9.8321905\n",
      "9.286905\n",
      "7.8663096\n",
      "7.1486235\n",
      "6.434574\n",
      "7.615304\n",
      "6.2233124\n",
      "5.891106\n",
      "5.6127553\n",
      "6.0298896\n",
      "4.6900806\n",
      "5.6410866\n",
      "4.190892\n",
      "4.7605786\n",
      "3.8219755\n",
      "3.9370568\n",
      "4.279015\n",
      "3.8470995\n",
      "3.143919\n",
      "4.0070662\n",
      "2.8145025\n",
      "3.2418168\n",
      "2.6417022\n",
      "2.5455596\n",
      "2.5386136\n",
      "2.9806478\n",
      "2.464143\n",
      "2.695445\n",
      "2.77966\n",
      "2.660437\n",
      "2.5104318\n",
      "2.1141922\n",
      "2.575287\n",
      "2.652555\n",
      "2.2257557\n",
      "1.6332338\n",
      "2.197292\n",
      "2.5026898\n",
      "2.235608\n",
      "2.5135107\n",
      "2.0827596\n",
      "2.3062208\n",
      "2.1084704\n",
      "2.7160363\n",
      "2.2956934\n",
      "1.895342\n",
      "2.4654255\n",
      "1.4585341\n",
      "1.8058511\n",
      "2.1038103\n",
      "2.2549686\n",
      "1.8889035\n",
      "1.159917\n",
      "1.8825428\n",
      "1.3570154\n",
      "2.0904365\n",
      "1.7879764\n",
      "2.1992357\n",
      "1.1618667\n",
      "1.7638595\n",
      "1.8645813\n",
      "1.325462\n",
      "1.4065607\n",
      "1.6055588\n",
      "1.3233048\n",
      "1.517059\n",
      "1.5202172\n",
      "1.8770517\n",
      "1.925462\n",
      "1.5864878\n",
      "1.1498439\n",
      "2.2059522\n",
      "1.4388951\n",
      "1.6337367\n",
      "1.796724\n",
      "1.7070689\n",
      "1.415786\n",
      "1.499295\n",
      "1.9212793\n",
      "1.7979361\n",
      "1.395206\n",
      "1.8703269\n",
      "1.6748674\n",
      "1.5769141\n",
      "1.1558908\n",
      "1.4059078\n",
      "1.0090175\n",
      "1.4571388\n",
      "1.0135617\n",
      "1.3928463\n",
      "1.0050179\n",
      "1.2536724\n",
      "1.1816459\n",
      "1.4630802\n",
      "1.5409964\n",
      "1.3632557\n",
      "1.6082234\n",
      "1.6162393\n",
      "1.3412174\n",
      "1.4676079\n",
      "1.820896\n",
      "1.861258\n",
      "1.2546487\n",
      "2.121061\n",
      "0.9055292\n",
      "1.3504057\n",
      "1.3807491\n",
      "1.6447432\n",
      "1.6632149\n",
      "1.7303932\n",
      "0.98094064\n",
      "1.337695\n",
      "1.9669273\n",
      "1.4983542\n",
      "1.374321\n",
      "0.8226743\n",
      "1.1169004\n",
      "1.055337\n",
      "2.0181339\n",
      "0.92409563\n",
      "1.3796797\n",
      "1.2534236\n",
      "1.8631421\n",
      "1.1866412\n",
      "1.2323182\n",
      "0.988788\n",
      "1.4690078\n",
      "1.3457245\n",
      "1.019624\n",
      "1.3258109\n",
      "1.2660398\n",
      "1.1220905\n",
      "1.0183251\n",
      "1.6044546\n",
      "0.82155913\n",
      "1.1755182\n",
      "1.2485374\n",
      "1.256693\n",
      "0.99559724\n",
      "1.5639147\n",
      "0.82618505\n",
      "1.1308388\n",
      "1.1372243\n",
      "0.99861664\n",
      "1.2711908\n",
      "1.0856\n",
      "0.87591887\n",
      "1.1036192\n",
      "0.9051576\n",
      "0.99870753\n",
      "1.2680986\n",
      "0.93668175\n",
      "1.0437742\n",
      "1.1575025\n",
      "1.5208398\n",
      "1.3769721\n",
      "1.2192183\n",
      "0.9674179\n",
      "1.1885004\n",
      "1.3877689\n",
      "0.9385065\n",
      "1.2276397\n",
      "1.266873\n",
      "1.1231445\n",
      "1.4613817\n",
      "1.069243\n",
      "0.944131\n",
      "0.94570154\n",
      "1.8981111\n",
      "0.9462823\n",
      "1.3273538\n",
      "1.0341885\n",
      "1.17677\n",
      "1.5396433\n",
      "0.9611917\n",
      "0.91952497\n",
      "0.7964804\n",
      "1.3172909\n",
      "1.1527561\n",
      "1.3189187\n",
      "0.9216551\n",
      "0.8804801\n",
      "0.90031815\n",
      "1.1194893\n",
      "1.7812195\n",
      "1.0979433\n",
      "0.6413945\n",
      "1.0274591\n",
      "1.239577\n",
      "0.95536554\n",
      "1.4491237\n",
      "0.7506498\n",
      "1.0849704\n",
      "1.255128\n",
      "1.1411965\n",
      "0.81347\n",
      "1.1172334\n",
      "1.0750729\n",
      "1.0317405\n"
     ]
    }
   ],
   "source": [
    "for batch_no in range(total_batches):\n",
    "    mnist_batch = mnist_data.train.next_batch(batch_size)\n",
    "    _, loss_value = session.run([optimizer, loss_operation], feed_dict={\n",
    "        x_input: mnist_batch[0],  # 입력 레이블\n",
    "        y_input: mnist_batch[1]   # 타깃 레이블\n",
    "    })\n",
    "    print(loss_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy :  0.812\n"
     ]
    }
   ],
   "source": [
    "# 모델이 잘 동작하는지 테스트\n",
    "# tf.argmax: 텐서 내의 지정된 축(0: 열, 1: 행, 2: 면)에서 가장 높은 값의 인덱스 반환\n",
    "\n",
    "# 정확도 계산\n",
    "# 1. 가장 큰 값의 인덱스가 예측값\n",
    "predictions = tf.argmax(logits, 1)\n",
    "# 2. 예측값과 정답이 일치하는지 비교\n",
    "correct_predictions = tf.equal(predictions, tf.argmax(y_input, 1))\n",
    "# 3. 일치 여부를 평균내어 정확도 계산\n",
    "accuracy_operation = tf.reduce_mean(tf.cast(correct_predictions,\n",
    "                                            tf.float32))\n",
    "test_images, test_labels = mnist_data.test.images, mnist_data.test.labels\n",
    "accuracy_value = session.run(accuracy_operation, feed_dict={\n",
    "    x_input: test_images,\n",
    "    y_input: test_labels\n",
    "})\n",
    "print('Accuracy : ', accuracy_value)\n",
    "session.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 다중 레이어 컨볼루션 신경망 구축하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 변수의 통계를 시각화하기 위해 tf.summary에 변수의 통계 값 추가\n",
    "def add_variable_summary(tf_variable, summary_name):\n",
    "    with tf.name_scope(summary_name + '_summary'):\n",
    "        mean = tf.reduce_mean(tf_variable)\n",
    "        tf.summary.scalar('Mean', mean)  # 평균\n",
    "        with tf.name_scope('standard_deviation'):\n",
    "            standard_deviation = tf.sqrt(tf.reduce_mean(  # √편차 제곱의 평균\n",
    "                tf.square(tf_variable - mean)))\n",
    "        tf.summary.scalar('StandardDeviation', standard_deviation)  # 표준 편차\n",
    "        tf.summary.scalar('Maximum', tf.reduce_max(tf_variable))  # 최대\n",
    "        tf.summary.scalar('Minimum', tf.reduce_min(tf_variable))  # 최소\n",
    "        tf.summary.histogram('Histogram', tf_variable)  # 히스토그램"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2차원 이미지 형태로 변경\n",
    "x_input_reshape = tf.reshape(x_input, [-1, 28, 28, 1],  # N X 28 X 28 X 1\n",
    "                             name='input_reshape')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 컨볼루션 레이어 정의\n",
    "def convolution_layer(input_layer, filters, kernel_size=[3, 3],\n",
    "                      activation=tf.nn.relu):\n",
    "    layer = tf.layers.conv2d(\n",
    "        inputs=input_layer,\n",
    "        filters=filters,\n",
    "        kernel_size=kernel_size,\n",
    "        activation=activation\n",
    "    )\n",
    "    add_variable_summary(layer, 'convolution')\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 풀링 레이어 정의\n",
    "def pooling_layer(input_layer, pool_size=[2, 2], strides=2):\n",
    "    layer = tf.layers.max_pooling2d(\n",
    "        inputs=input_layer,\n",
    "        pool_size=pool_size,\n",
    "        strides=strides\n",
    "    )\n",
    "    add_variable_summary(layer, 'pooling')\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fully-connected 레이어 정의\n",
    "def dense_layer(input_layer, units, activation=tf.nn.relu):\n",
    "    layer = tf.layers.dense(\n",
    "        inputs=input_layer,\n",
    "        units=units,\n",
    "        activation=activation)\n",
    "    add_variable_summary(layer, 'dense')\n",
    "    return layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# n개의 필터를 적용하면 feature map도 n개의 채널을 가짐\n",
    "\n",
    "# 출력의 크기\n",
    "# N X 26 X 26 X 64\n",
    "convolution_layer_1 = convolution_layer(x_input_reshape, 64)\n",
    "# N X 13 X 13 X 64\n",
    "pooling_layer_1 = pooling_layer(convolution_layer_1)\n",
    "# N X 11 X 11 X 128\n",
    "convolution_layer_2 = convolution_layer(pooling_layer_1, 128)\n",
    "# N X 5 X 5 X 128 (마지막 열/행이 잘림)\n",
    "pooling_layer_2 = pooling_layer(convolution_layer_2)\n",
    "# Dense Layer로 Pooling Layer의 출력을 넘기기 위해 텐서를 평평하게 함\n",
    "flattened_pool = tf.reshape(pooling_layer_2, [-1, 5 * 5 * 128],\n",
    "                            name='flattened_pool')\n",
    "dense_layer_bottleneck = dense_layer(flattened_pool, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropout: 학습을 할 때마다 임의의 unit을 삭제하는 정규화 방법\n",
    "dropout_bool = tf.placeholder(tf.bool)\n",
    "dropout_layer = tf.layers.dropout(\n",
    "    inputs=dense_layer_bottleneck,\n",
    "    rate=0.4,\n",
    "    training=dropout_bool\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = dense_layer(dropout_layer, no_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.name_scope('loss'):\n",
    "    softmax_cross_entropy = tf.nn.softmax_cross_entropy_with_logits(\n",
    "        labels=y_input, logits=logits)\n",
    "    loss_operation = tf.reduce_mean(softmax_cross_entropy, name='loss')\n",
    "    tf.summary.scalar('loss', loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss 함수 최적화\n",
    "with tf.name_scope('optimizer'):\n",
    "    optimizer = tf.train.AdamOptimizer().minimize(loss_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'accuracy_1:0' shape=() dtype=string>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 정확도 계산\n",
    "with tf.name_scope('accuracy'):\n",
    "    with tf.name_scope('correct_prediction'):\n",
    "        predictions = tf.argmax(logits, 1)\n",
    "        correct_predictions = tf.equal(predictions, tf.argmax(y_input, 1))\n",
    "    with tf.name_scope('accuracy'):\n",
    "        accuracy_operation = tf.reduce_mean(\n",
    "            tf.cast(correct_predictions, tf.float32))\n",
    "tf.summary.scalar('accuracy', accuracy_operation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "session = tf.Session()\n",
    "session.run(tf.global_variables_initializer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 앞서 지정한 모든 summary를 넣음\n",
    "merged_summary_operation = tf.summary.merge_all()\n",
    "train_summary_writer = tf.summary.FileWriter('/tmp/train', session.graph)\n",
    "test_summary_writer = tf.summary.FileWriter('/tmp/test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_images, test_labels = mnist_data.test.images, mnist_data.test.labels\n",
    "\n",
    "for batch_no in range(total_batches):\n",
    "    mnist_batch = mnist_data.train.next_batch(batch_size)\n",
    "    train_images, train_labels = mnist_batch[0], mnist_batch[1]\n",
    "    _, merged_summary = session.run([optimizer, merged_summary_operation],\n",
    "                                    feed_dict={\n",
    "                                        x_input: train_images,\n",
    "                                        y_input: train_labels,\n",
    "                                        dropout_bool: True\n",
    "                                    })\n",
    "    train_summary_writer.add_summary(merged_summary, batch_no)\n",
    "    \n",
    "    if batch_no % 10 == 0:\n",
    "        merged_summary, _ = session.run([merged_summary_operation,\n",
    "                                        accuracy_operation], feed_dict={\n",
    "            x_input: test_images,\n",
    "            y_input: test_labels,\n",
    "            dropout_bool: False\n",
    "        })\n",
    "        test_summary_writer.add_summary(merged_summary, batch_no)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
